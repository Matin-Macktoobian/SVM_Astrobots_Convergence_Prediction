{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "# Import from the standard Python libraries\n",
    "import math\n",
    "import re\n",
    "#import simplejson\n",
    "import json as simplejson\n",
    "import numpy as np\n",
    "import ntpath\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.io\n",
    "import seaborn as sn\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Mauro\\Master Thesis\\SVM_Data_7Pos'\n",
    "os.chdir(path)\n",
    "\n",
    "list = os.listdir(path) # dir is your directory path\n",
    "number_files = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central algorithm SVM\n",
    "\n",
    "prediction_results=np.empty((0,8))\n",
    "\n",
    "for i in range (1,number_files+1):\n",
    "    \n",
    "    #Open the data\n",
    "    Data = Open_Data_File(i)\n",
    "    \n",
    "    #dividing attributes from labels\n",
    "    X=Data.drop('label',axis=1)\n",
    "    y=Data['label']\n",
    "    \n",
    "    n_of_attributes = X.shape[1]\n",
    "    \n",
    "    #number of neighbours of the astrobots (considering parity)\n",
    "    n_neigh = (n_of_attributes - 3)/3\n",
    "    #print(n_neigh)\n",
    "    \n",
    "    #Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "    \n",
    "    #Average distance between vectors\n",
    "    #avg_dist = Average_euclidean_distance(X_train)\n",
    "    #print(avg_dist)\n",
    "    \n",
    "    #SVC predictor\n",
    "    \n",
    "    if n_neigh == 6:\n",
    "        GAMMA = 0.0009\n",
    "        w1 = 1/90 \n",
    "    elif n_neigh == 3:\n",
    "        GAMMA = 0.0018\n",
    "        w1 = 1/120\n",
    "        \n",
    "    \n",
    "    #Building and training the predictor\n",
    "    svclassifier = SVC(kernel='rbf', C=100, class_weight={1: w1}, gamma=GAMMA)\n",
    "    svclassifier.fit(X_train, y_train)\n",
    "    \n",
    "    #Evaluate prediction\n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    TPR=tp/(tp+fn)\n",
    "    TNR=tn/(tn+fp)\n",
    "    BalAcc=(TPR + TNR)/2\n",
    "\n",
    "    #print('True positive rate: ', TPR, '\\n')\n",
    "    #print('True negative rate: ', TNR, '\\n')\n",
    "    #print('balanced accuracy : ', BalAcc, '\\n')\n",
    "    \n",
    "    \n",
    "    info_vec = np.array([n_neigh, tp, tn, fp, fn, TPR, TNR, BalAcc])\n",
    "    print(info_vec)\n",
    "\n",
    "    prediction_results=np.vstack((prediction_results, info_vec))\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    #wait = input(\"PRESS ENTER TO CONTINUE.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.26714286e+03 2.40285714e+02 1.03142857e+02 3.89428571e+02\n",
      " 8.53191450e-01 7.21967458e-01 7.87579454e-01]\n",
      "15870.0 1682.0 722.0 2726.0\n"
     ]
    }
   ],
   "source": [
    "prediction_results.shape\n",
    "\n",
    "mean_results = np.mean(prediction_results[:,1:8], axis=0)\n",
    "print(mean_results)\n",
    "\n",
    "TP_tot=np.sum(prediction_results[:,1])\n",
    "TN_tot=np.sum(prediction_results[:,2])\n",
    "FP_tot=np.sum(prediction_results[:,3])\n",
    "FN_tot=np.sum(prediction_results[:,4])\n",
    "\n",
    "print(TP_tot, TN_tot, FP_tot, FN_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Open_Data_File(num):\n",
    "    \n",
    "    #Read csv data \n",
    "    \n",
    "    str_file = '7Pos_astrobot' + str(num) + '.csv'\n",
    "    Data = pd.read_csv(str_file)\n",
    "    return(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_euclidean_distance(X_train):\n",
    "\n",
    "    #This function compute an average of the euclidean distance between a sample of vectors\n",
    "    # in order to have a first indication of what should be the order of magnitude of the kernel size\n",
    "    \n",
    "    size = X_train.shape[0]\n",
    "    dist_vec=[]\n",
    "    for i in range(0,round(size/600)):\n",
    "    \n",
    "        x1=X_train.to_numpy()[i]\n",
    "        #print(x1)\n",
    "    \n",
    "        for j in range(0,round(size/600)):\n",
    "        \n",
    "            x2=X_train.to_numpy()[j]\n",
    "            #print(x2)\n",
    "        \n",
    "            if np.array_equal(x1,x2):\n",
    "                continue\n",
    "            else:\n",
    "                d = np.linalg.norm(x1-x2)\n",
    "                dist_vec=np.append(dist_vec, d)\n",
    "            \n",
    "    \n",
    "\n",
    "    #print(np.mean(dist_vec))\n",
    "    return np.mean(dist_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
